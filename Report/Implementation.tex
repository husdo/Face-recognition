\subsection{The Graphical User Interface}

To make our program simple and easy to use, we have created a Graphical User Interface(GUI). To do so we have used the Qt library and because it can 
generate problems on some computers, the program can also be run without GUI by specifying the training and testing folders in the command line.
The GUI is divided into 3 main parts: the main window, the result dialogBox and the ImageCapture program.

\subsubsection{The main window}

It is the first window to appear when the program is executed. It contains the following functionalities:
\begin{itemize}
 \item A menu to load and save classifiers in a file (the classifier selected in the list of methods will be used) and to run the ImageCapture 
program.

\item A path selection tool to specify where is are the training and validation folders. The paths can be modified directly from the text inputs or 
by browsing it using the "..." button.

\item A widget displaying the image retrieved from the webcam. A Rectangle has been added to help the user to center his face on the picture.
\item An output console embedded in the window.
\item A normalization checkbox to apply the normalization on the images or not
\item A progressBar to make sure that the program is still running while loading the images (unfortunately it was not possible to do the same for the 
training).
\end{itemize}

\subsubsection{The result dialogBox}
When a new picture is taken by the user, a new result window is created. This dialogBox call the predict function from the selected classifier and 
display the results to the user(image, predicted label and confidence level).

\subsubsection{The ImageCapture program}
- Drag'n Drop square
- Big cross for alignment
- Space Bar to record

\subsubsection{The Webcam object}

\subsection{Dataset}
\subsubsection{Databases used}
During the project, we used different databases :
\begin{itemize}
 \item The database provided by the AT\&T laboratory in Cambridge
\item The Yale database. These two first databases were mainly used to carry out the first tests as the images were already prepared (grayscale, right size, faces centered with different illuminations).
\item The caltech database to test the preparation of the images and the methods on faces in front of different backgrounds, illuminations without any preprocessing.
\item Databases on the faces of the people in the group project. (Personal database)
\end{itemize}
\subsubsection{Acquisition of our own Dataset}
Dataset used for training :
\begin{itemize}
 \item 3 persons, 100 pictures for each from 1 take.  
\item 3 persons, 100 pictures for each from 3 take.
\item 3 persons, 10 pictures for each from 3 take.
\item 5 persons, 10 pictures for each from 5 take.
\end{itemize}
We firstly tried to do a little database with only three people selected from the group. We wanted to have the faces exposed to different illuminations and in front of different background to avoid a recognition valid only under certain conditions. The process was to make different faces (smiling, opening the mouth...) in different places. A video was then taken while moving the face and the computer in a partially lighted room in order to get different illuminations. 

We have broken down our initial dataset into two folders: a training folder and a testing one. Firstly, we respected a 80\%, 20\% repartition between the training and validation dataset. However, there was too many images for each person in the training dataset and we experienced overfitting. Indeed, if the training and validation test were the same, results were good. If we took other images for the validation, the results could be less efficient than a random choice ($<$30\% in the first database), or recognize a type of illumination instead of a person.

The most efficient training set was approximately 10 images taken in different conditions. 

\subsection{Preprocessing}
It is known that Eigenfaces and Fisherfaces were sensible to rotation. To maximize the recognition, a preprocessing of the faces was made and consisted in getting a centered, straight head in a known size image. However the Haar detection can take up to 1 second, and the rotation and cropping on the initial colour image up to 0.3 seconds. (The colour image was kept in order to use the colour on other methods not yet implemented in the project). The time of processing prevent doing some real time recognition. The recognition with normalization of the images on a 3 person database jumped from 21\% to 89\% of recognized face.

To improve our results, we also try to equalize the histogram of the gray image before the analyze of it. As there was no improvement of recognition and as it took some processing time, we stopped the equalization.

\subsection{Methods}

To implement the methods we created three base class. The image handler(images.h), the recognizer (Facial\_Recogniser.h) and the normalizer (normalizer.h).
\begin{itemize}
	\item The $Images$ class encapsulate the images. It can read from a folder or it's possible to add only a $Mat$ file with label. It also contains the labels for the pictures.
	
	\item The $Facial\_Recognizer$ is a base class. It has multiple virtual functions to make the interfaces universal. These functions are: train, load, save and predict. It has a validation part witch test the classifier with a set of images and save the result of the validation into cvs file.
	
	\item normalizer.h
	The normalizer just read the original image and gives back the normalised one. If the normalization fails the original picture will be stored.
	
\end{itemize}

\subsection{Testing parameters}

\subsection{Loading and Saving}
To have an easier loading of the model through the GUI interface, there is only one file to load. It is a merge of two files : An xml file representing the model itself and a csv file representing the linking between labels (integer) and names associated.
